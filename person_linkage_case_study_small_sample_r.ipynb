{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed9e49e5-db4e-4665-9892-0a679dcc22c5",
   "metadata": {},
   "source": [
    "# **Person linkage case study with small-scale sample data**\n",
    "\n",
    "In this case study, we imagine running a person linkage to add unique identifiers to a simulated 2030 Census Unedited File (CUF).\n",
    "We emulate the methods of the Census Bureau's Person Identification Validation System (PVS) using publicly available descriptions.\n",
    "The PVS aims to give people in the input file (the CUF, in this case) unique identifiers that can be used to link them to other administrative records.\n",
    "\n",
    "We approximate the (highly confidential) input data to PVS by using simulated data from our pseudopeople package.\n",
    "See the `generate_simulated_data` notebook for details about this.\n",
    "\n",
    "## Sources\n",
    "\n",
    "These papers describe PVS as their main subject:\n",
    "\n",
    "* Wagner and Layne. The Person Identification Validation System (PVS): Applying the Center for Administrative Records Research and Applications’ (CARRA) Record Linkage Software. 2014. https://www.census.gov/content/dam/Census/library/working-papers/2014/adrm/carra-wp-2014-01.pdf ([archived](https://web.archive.org/web/20230216043235/https://www.census.gov/content/dam/Census/library/working-papers/2014/adrm/carra-wp-2014-01.pdf))\n",
    "* Layne, Wagner, and Rothhaas. Estimating Record Linkage False Match Rate for the Person Identification Validation System. 2014. https://www.census.gov/content/dam/Census/library/working-papers/2014/adrm/carra-wp-2014-02.pdf ([archived](https://web.archive.org/web/20220121051156/https://www.census.gov/content/dam/Census/library/working-papers/2014/adrm/carra-wp-2014-02.pdf))\n",
    "* Alexander et al. Creating a Longitudinal Data Infrastructure at the Census Bureau. 2015. https://www.census.gov/content/dam/Census/library/working-papers/2015/adrm/2015-alexander.pdf ([archived](https://web.archive.org/web/20170723192315/http://www.census.gov/content/dam/Census/library/working-papers/2015/adrm/2015-alexander.pdf))\n",
    "* Massey and O'Hara. Person Matching in Historical Files using the Census Bureau’s Person Validation System. 2014. https://www.census.gov/content/dam/Census/library/working-papers/2014/adrm/carra-wp-2014-11.pdf ([archived](https://web.archive.org/web/20221018074814/http://www.census.gov/content/dam/Census/library/working-papers/2014/adrm/carra-wp-2014-11.pdf))\n",
    "* NORC. Assessment of the U.S. Census Bureau’s Person Identification Validation System. 2011. https://www.norc.org/content/dam/norc-org/pdfs/PVS%20Assessment%20Report%20FINAL%20JULY%202011.pdf ([archived](https://web.archive.org/web/20230705005935/https://www.norc.org/content/dam/norc-org/pdfs/PVS%20Assessment%20Report%20FINAL%20JULY%202011.pdf))\n",
    "\n",
    "These apply PVS to some linking task, and in doing so describe it in some detail:\n",
    "\n",
    "* Brown et al. Real-Time 2020 Administrative Record Census Simulation. 2023. https://www2.census.gov/programs-surveys/decennial/2020/program-management/evaluate-docs/EAE-2020-admin-records-experiment.pdf ([archived](https://web.archive.org/web/20230521191811/https://www2.census.gov/programs-surveys/decennial/2020/program-management/evaluate-docs/EAE-2020-admin-records-experiment.pdf))\n",
    "* Massey et al. Linking the 1940 U.S. Census with Modern Data. 2018. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6530596/ ([DOI](https://doi.org/10.1080%2F01615440.2018.1507772))\n",
    "* Luque and Wagner. Assessing Coverage and Quality of the 2007 Prototype Census Kidlink Database. 2015. https://www.census.gov/content/dam/Census/library/working-papers/2015/adrm/carra-wp-2015-07.pdf ([archived](https://web.archive.org/web/20220808205231/http://www.census.gov/content/dam/Census/library/working-papers/2015/adrm/carra-wp-2015-07.pdf))\n",
    "* Bond et al. The Nature of the Bias When Studying Only Linkable Person Records: Evidence from the American Community Survey. 2014. https://www.census.gov/content/dam/Census/library/working-papers/2014/adrm/carra-wp-2014-08.pdf ([archived](https://web.archive.org/web/20220803083857/http://www.census.gov/content/dam/Census/library/working-papers/2014/adrm/carra-wp-2014-08.pdf))\n",
    "\n",
    "Finally, this paper is about the address matching process (MAF Match) which acts as part of PVS:\n",
    "\n",
    "* Brummet. Comparison of Survey, Federal, and Commercial Address Data Quality. 2014. https://www.census.gov/content/dam/Census/library/working-papers/2014/adrm/carra-wp-2014-06.pdf ([archived](https://web.archive.org/web/20220121213358/https://www.census.gov/content/dam/Census/library/working-papers/2014/adrm/carra-wp-2014-06.pdf))\n",
    "\n",
    "All of these papers are referenced throughout this notebook (and other notebooks) by the authors' names, along with additional information like page numbers.\n",
    "All page numbers represent those of the PDF files themselves, *not* page numbers printed in the documents.\n",
    "\n",
    "## PVS overview\n",
    "\n",
    "Brown et al., p. 28:\n",
    "\n",
    "> The PVS uses probabilistic record linkage (Fellegi and Sunter, 1969) to match data from an\n",
    "    incoming file (e.g., a survey or administrative record file) to reference files containing data on\n",
    "    SSN applications from the NUMIDENT enhanced with address data obtained from other federal\n",
    "    administrative records.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0af1f28-7e30-4860-992e-15da22f9b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, copy, os\n",
    "import pandas as pd, numpy as np\n",
    "import jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47bc4e2e-93cb-47f1-b4ab-fedac26382b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use = 'small_sample'\n",
    "input_dir = 'generate_simulated_data/output'\n",
    "output_dir = 'output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8c9a9-d691-4110-baed-683004701894",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "See code in `generate_simulated_data` directory for how we generated the files to link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf1086b-639c-4421-95ef-dc4108b7fd9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "census_2030 = pd.read_parquet(f'{input_dir}/{data_to_use}/simulated_census_2030.parquet')\n",
    "geobase_reference_file = pd.read_parquet(f'{input_dir}/{data_to_use}/simulated_geobase_reference_file.parquet')\n",
    "name_dob_reference_file = pd.read_parquet(f'{input_dir}/{data_to_use}/simulated_name_dob_reference_file.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc6d16d-f4c9-4c1a-b969-baee5ac539ad",
   "metadata": {},
   "source": [
    "# Pre-process input file\n",
    "\n",
    "Wagner and Layne, p. 9:\n",
    "\n",
    "> The first step of the PVS process is to edit data fields to make them homogenous for\n",
    "comparisons between incoming and reference files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0111f6-d8e0-4758-a242-70027d67b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file before any processing; the final result will be this with the PIK column added\n",
    "census_2030_raw_input = census_2030.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829cf59a-804c-4372-bcbf-740ec724b3ee",
   "metadata": {},
   "source": [
    "## Name parsing and standardizing\n",
    "\n",
    "Wagner and Layne, p. 9:\n",
    "\n",
    "> The first edits are parsing and standardizing - parsing separates fields into\n",
    "component parts, while standardizing guarantees key data elements are consistent (e.g.,\n",
    "STREET, STR are both converted to ST). Name and address fields are parsed and\n",
    "standardized as they are key linkage comparators. \n",
    "\n",
    "As noted in the data generation notebook, there is no parsing to be done here:\n",
    "because the Census questionnnaire asks for first name, middle initial, and last name as\n",
    "separate fields on the form, the name would be already parsed when running PVS on the CUF.\n",
    "\n",
    "The real PVS name parser generates fields like prefix (e.g. Mr.) and suffix (e.g. Jr.)\n",
    "but we never have these in names from pseudopeople.\n",
    "\n",
    "More details about the name parser and standardizer (Wagner and Layne, p. 10):\n",
    "\n",
    "> The PVS system incorporates a name\n",
    "standardizer (McGaughey, 1994), which is a C language subroutine called as a function\n",
    "within SAS. It performs name parsing and includes a nickname lookup table and outputs\n",
    "name variants (standardized variations of first and last names). For example, Bill\n",
    "becomes William, Chuck and Charlie becomes Charles, etc. The PVS keeps both the\n",
    "original name (Bill) and the converted name (William) for matching. PVS also has a fake\n",
    "name table to blank names such as “Queen of the House” or “Baby Girl.” The name data\n",
    "are parsed, checked for nicknames, and standardized.\n",
    "\n",
    "The key thing that wasn't clear to me from this description was what it meant to\n",
    "\"keep both original name and the converted name for matching.\"\n",
    "I found this in Massey et al.:\n",
    "\n",
    "> The Name Search Module also accounts for instances where census records contain a nickname.\n",
    "> For these records, the preprocessing step of the Name Search module outputs two records for\n",
    "> these observations, one record for the nickname and one record for the formal name.\n",
    "> For example, if the input record has the name “Bill Smith,” the formatting program will add\n",
    "> a formal name “William” to that record. This record will then output to both the B-S cut and to the W-S cut.\n",
    "\n",
    "From this, I gather that nicknames work similar to alternate names in the reference file:\n",
    "entire duplicate records are made with each name (nickname and formal).\n",
    "However, I am still confused by calling this \"the preprocessing step **of the Name Search module**.\"\n",
    "In Wagner and Layne it does not seem like this is module-specific, and I don't see any\n",
    "reason that would be desirable, so I have done this multi-record approach across all modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e07e300-2277-40bf-bfb5-67080c0b6578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 nicknames in the Census\n"
     ]
    }
   ],
   "source": [
    "# Nickname processing\n",
    "# Have not yet found a nickname list in PVS docs,\n",
    "# so we do a minimal version for now -- could use\n",
    "# another list such as the one in pseudopeople\n",
    "# These examples all come directly from examples in the descriptions of PVS\n",
    "nickname_standardizations = {\n",
    "    \"Bill\": \"William\",\n",
    "    \"Chuck\": \"Charles\",\n",
    "    \"Charlie\": \"Charles\",\n",
    "    \"Cathy\": \"Catherine\",\n",
    "    \"Matt\": \"Matthew\",\n",
    "}\n",
    "has_nickname = census_2030.first_name.isin(nickname_standardizations.keys())\n",
    "print(f'{has_nickname.sum()} nicknames in the Census')\n",
    "\n",
    "# Add extra rows for the normalized names\n",
    "census_2030 = pd.concat([\n",
    "    census_2030,\n",
    "    census_2030[has_nickname].assign(first_name=lambda df: df.first_name.replace(nickname_standardizations))\n",
    "], ignore_index=True)\n",
    "\n",
    "# Note: The above will introduce duplicates on record_id, so we redefine\n",
    "# record_id to be unique (without getting rid of the original, input file record ID)\n",
    "def add_unique_record_id(df, dataset_name):\n",
    "    df = df.reset_index().rename(columns={'index': 'record_id'})\n",
    "    df['record_id'] = f'{dataset_name}_' + df.record_id.astype(str)\n",
    "    return df\n",
    "\n",
    "census_2030 = add_unique_record_id(\n",
    "    census_2030.rename(columns={'record_id': 'record_id_raw_input_file'}),\n",
    "    \"census_2030_preprocessed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e3beca-5d4e-4d58-a65f-1c6bda2ea02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        (CONFIDENTIAL)\n",
       "1      (NO MIDDLE NAME)\n",
       "2           A RELUCTANT\n",
       "3                 ADULT\n",
       "4               ADULT F\n",
       "             ...       \n",
       "766       YOUNGEST DAUG\n",
       "767       YOUNGEST GIRL\n",
       "768              YR BOY\n",
       "769             YR GIRL\n",
       "770              YR OLD\n",
       "Length: 771, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This list of fake names comes from the NORC report, p. 100-101\n",
    "# It is what was used in PVS as of 2011\n",
    "with open('fake-names.txt') as f:\n",
    "    fake_names = pd.Series([name.strip().upper() for name in f.readlines()])\n",
    "\n",
    "assert (fake_names == fake_names.str.upper()).all()\n",
    "fake_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f234ee61-5d2a-490e-97ad-eff72df732ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 fake names in first_name\n",
      "Found 57 fake names in last_name\n"
     ]
    }
   ],
   "source": [
    "for col in [\"first_name\", \"last_name\"]:\n",
    "    has_fake_name = census_2030[col].str.upper().isin(fake_names)\n",
    "    print(f'Found {has_fake_name.sum()} fake names in {col}')\n",
    "    census_2030[col] = np.where(\n",
    "        has_fake_name,\n",
    "        np.nan,\n",
    "        census_2030[col]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26659727-027b-4daf-8921-1fdb4b5e4d54",
   "metadata": {},
   "source": [
    "## Address parsing and standardizing\n",
    "\n",
    "Wagner and Layne, p. 11:\n",
    "\n",
    "> The PVS editing process also incorporates an address parser and standardizer,\n",
    "written in the C language and called as a function within SAS (U.S. Census Bureau\n",
    "Geography Division, 1995). It performs parsing of address strings into individual output\n",
    "fields (see Figure 2), and standardizes the spelling of key components of the address\n",
    "such as street type. The PVS also incorporates use of a commercial product to update\n",
    "zip codes, and correct misspellings of address elements.\n",
    "\n",
    "As noted in the data generation notebook, for now we haven't combined the address parts\n",
    "into a single string that would need to be parsed.\n",
    "We plan to add this in a future version of pseudopeople.\n",
    "\n",
    "For now, we do some simple standardization in each of the address parts (street number,\n",
    "street name, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9435bc12-0002-44bc-91e3-26083d95c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_address_part(column):\n",
    "    return (\n",
    "        column\n",
    "            # Remove leading or trailing whitespace\n",
    "            .str.strip()\n",
    "            # Turn any strings of consecutive whitespace into a single space\n",
    "            .str.split().str.join(' ')\n",
    "            # Normalize case\n",
    "            .str.upper()\n",
    "            # Normalize the word street as described in the example quoted from\n",
    "            # Wagner and Layne p. 9\n",
    "            # In reality, there would be many rules like this\n",
    "            .str.replace('\\b(STREET|STR)\\b', 'ST', regex=True)\n",
    "            # Make sure missingness is represented consistently\n",
    "            .replace('', np.nan)\n",
    "    )\n",
    "\n",
    "address_cols = ['street_number', 'street_name', 'unit_number', 'city', 'state', 'zipcode']\n",
    "census_2030[address_cols] = census_2030[address_cols].apply(standardize_address_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b55b52-c3ad-41da-9351-05ef56927dbf",
   "metadata": {},
   "source": [
    "## MAFMatch\n",
    "\n",
    "**General information about MAFMatch**\n",
    "\n",
    "Wagner and Layne, p. 11:\n",
    "\n",
    "> The PVS provides an additional address enhancement by matching records in the\n",
    "incoming file to Census Bureau’s Master Address File (MAF) in order to assign a unique\n",
    "address identifier, the MAF Identifier (MAFID), and other Census geographical codes\n",
    "(e.g., Census tract and block). The MAFID is used in the PVS for search purposes and as a\n",
    "linkage key for administrative files. Then, addresses are matched to the Census Bureau’s\n",
    "Topologically Integrated Geographic Encoding and Referencing Database (TIGER) to\n",
    "obtain Census geographical codes.\n",
    "\n",
    "My understanding is that this step is useful for two reasons:\n",
    "- Potentially adds an alternate version/way of formatting the same address\n",
    "  (the way it is in the MAF, instead of the way it is in the input file).\n",
    "  However, instead of using this alternate to match directly, it is boiled down\n",
    "  to a MAFID, so it is only useful when an input file address and a reference file\n",
    "  address (different to one another) both match to the same MAF address.\n",
    "  (Presumably, the whole MAFMatch process described here needs to run on the reference files?)\n",
    "- Adds Census geographies which could be used in blocking (but are they?)\n",
    "\n",
    "I don't understand the TIGER part of this.\n",
    "In particular, p. 12 describes a probabilistic/fuzzy match to TIGER, but I thought TIGER\n",
    "would contain exactly the same addresses as the MAF.\n",
    "I also don't understand what geocodes would be present in TIGER that wouldn't also be\n",
    "present in the MAF.\n",
    "Maybe these things are more out-of-sync with each other than I understood.\n",
    "\n",
    "**MAFMatch in this case study**\n",
    "\n",
    "In the decennial Census, the sampling frame is a subset of the MAF (Brown et al., p. 15, footnote 4).\n",
    "That is, in the CUF, the address field (which is not supplied by the respondent)\n",
    "would be the MAF address the questionnaire/NRFU was sent to.\n",
    "\n",
    "Therefore, I don't believe it makes sense to do MAFMatch for the CUF, because all the addresses\n",
    "are already the same.\n",
    "I haven't fully confirmed this, but p. 14 of Wagner and Layne says\n",
    "\n",
    "> The 2010 Census Unedited File (CUF), had 350 million records and processed through every PVS\n",
    "module, excluding MAF match and SSN verification\n",
    "\n",
    "which suggests that (like SSN verification) MAFMatch is not applicable to the CUF.\n",
    "\n",
    "Given this, we skip MAFMatch here.\n",
    "Also, if we wanted to add it, we would need to generate something like a MAF from pseudopeople."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ec2c6-a028-4f36-a041-63627fb60fd6",
   "metadata": {},
   "source": [
    "## Drop records with insufficient information\n",
    "\n",
    "In 2011 (NORC, p. 25):\n",
    "\n",
    "> The initial edit process, described in the Introduction: PVS Background section, removes from consideration\n",
    "incoming records that have no name data. Therefore, no record that is processed in PVS has blank first and last\n",
    "names.\n",
    "\n",
    "In 2014 it appears to be the same/similar, because in Table 2 of Wagner and Layne there is a row \"NO SEARCH: Blank Name\" (p. 18).\n",
    "\n",
    "In 2023 (Brown et al., p. 28):\n",
    "\n",
    "> Records containing sufficient PII to be linkable with some confidence, for example those\n",
    "containing name and age, are sent through the linkage process.<sup>15</sup>\n",
    "\n",
    "> <sup>15</sup> Records with names on the PVS invalid name list (e.g., “Mickey Mouse,” “householder,” or “son”) are excluded\n",
    "from PVS search.\n",
    "\n",
    "I'd prefer to use the 2023 information, but it is too vague:\n",
    "\"for example\" means this is just an approximation, and it doesn't specify\n",
    "parts of \"name.\"\n",
    "The footnote also seems to contradict earlier reports, which said fake names were simply\n",
    "blanked out, which seems preferable.\n",
    "Since the fake name step comes before this one, a fake first **and** last name would lead\n",
    "to exclusion here, which is perhaps what the footnote was intending?\n",
    "\n",
    "Here, we follow the blank-name approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "277c1379-c46b-4a0f-8011-596efae84778",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2030 = census_2030[\n",
    "    census_2030.first_name.notnull() |\n",
    "    census_2030.last_name.notnull()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a91f7-e733-4a3d-bd56-7e23b0c8d138",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create derived variables for use in linkage\n",
    "\n",
    "Here we create variables to be used as matching variables and blocking keys,\n",
    "when those matching variables/blocking keys are defined in a way that is not already\n",
    "present in the data at this point.\n",
    "\n",
    "The variables needed here depend on the modules and passes described below -- see those\n",
    "sections for more citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edb97b21-8ca1-4ad3-bae1-dbf7dc0bee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to compare mailing address with physical address\n",
    "geobase_reference_file = geobase_reference_file.rename(columns=lambda c: c.replace('mailing_address_', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c61c2257-a840-498a-9aa5-0788f9763634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PVS uses DOB as separate fields for day, month, and year\n",
    "def split_dob(df, date_format='%Y%m%d'):\n",
    "    df = df.copy()\n",
    "    # Have to be floats because we want to treat as numeric for assessing similarity\n",
    "    # Note that as of now, none of our pseudopeople noise types would change the punctuation (\"/\") in the date, but\n",
    "    # they can insert non-numeric characters here or otherwise create invalid dates, in which case we fail to parse the date\n",
    "    # and treat it as missing.\n",
    "    dob = pd.to_datetime(df.date_of_birth, format=date_format, errors='coerce')\n",
    "    df['month_of_birth'] = dob.dt.month\n",
    "    df['year_of_birth'] = dob.dt.year\n",
    "    df['day_of_birth'] = dob.dt.day\n",
    "    return df.drop(columns=['date_of_birth'])\n",
    "\n",
    "census_2030 = split_dob(census_2030, date_format='%m/%d/%Y')\n",
    "geobase_reference_file = split_dob(geobase_reference_file)\n",
    "name_dob_reference_file = split_dob(name_dob_reference_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55126ed5-94e3-4713-badd-9861f5c6ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't fully understand the purpose of blocking on the geokey,\n",
    "# as opposed to just blocking on its constituent columns.\n",
    "# Maybe it is a way of dealing with missingness in those constituent\n",
    "# columns (e.g. so an address with no unit number can still be blocked on geokey)?\n",
    "def add_geokey(df):\n",
    "    df = df.copy()\n",
    "    df['geokey'] = (\n",
    "        df.street_number + ' ' +\n",
    "        df.street_name + ' ' +\n",
    "        df.unit_number.fillna('') + ' ' +\n",
    "        df.city + ' ' +\n",
    "        df.state.astype(str) + ' ' +\n",
    "        df.zipcode\n",
    "    )\n",
    "    # Normalize the whitespace -- necessary if the unit number was null\n",
    "    df['geokey'] = (\n",
    "        df.geokey.str.split().str.join(' ')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "geobase_reference_file = add_geokey(geobase_reference_file)\n",
    "census_2030 = add_geokey(census_2030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6894cbdd-fef2-417d-a69f-3e15433c1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layne, Wagner, and Rothhaas p. 26: the name matching variables are\n",
    "# First 15 characters First Name, First 15 characters Middle Name, First 12 characters Last Name\n",
    "# Additionally, there are blocking columns for all of 1-3 initial characters of First/Last.\n",
    "# We don't have a full middle name in pseudopeople (nor would that be present in a real CUF)\n",
    "# so we have to stick to the first initial for middle.\n",
    "def add_truncated_name_cols(df):\n",
    "    df = df.copy()\n",
    "    df['first_name_15'] = df.first_name.str[:15]\n",
    "    df['last_name_12'] = df.last_name.str[:12]\n",
    "\n",
    "    if 'middle_name' in df.columns and 'middle_initial' not in df.columns:\n",
    "        df['middle_initial'] = df.middle_name.str[:1]\n",
    "\n",
    "    for num_chars in [1, 2, 3]:\n",
    "        df[f'first_name_{num_chars}'] = df.first_name.str[:num_chars]\n",
    "        df[f'last_name_{num_chars}'] = df.last_name.str[:num_chars]\n",
    "\n",
    "    return df\n",
    "\n",
    "census_2030 = add_truncated_name_cols(census_2030)\n",
    "geobase_reference_file = add_truncated_name_cols(geobase_reference_file)\n",
    "name_dob_reference_file = add_truncated_name_cols(name_dob_reference_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c29dcc81-9056-459b-80f6-fd32125913bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layne, Wagner, and Rothhaas p. 26: phonetics are used in blocking (not matching)\n",
    "# - Soundex for Street Name\n",
    "# - NYSIIS code for First Name\n",
    "# - NYSIIS code for Last Name\n",
    "# - Reverse Soundex for First Name\n",
    "# - Reverse Soundex for Last Name\n",
    "\n",
    "def add_name_phonetics(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in ['first_name', 'last_name']:\n",
    "        df[f'{col}_nysiis'] = df[col].dropna().apply(jellyfish.nysiis)\n",
    "        df[f'{col}_reverse_soundex'] = df[col].dropna().str[::-1].apply(jellyfish.soundex)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_address_phonetics(df):\n",
    "    df = df.copy()\n",
    "    df['street_name_soundex'] = df.street_name.dropna().apply(jellyfish.soundex)\n",
    "    return df\n",
    "\n",
    "census_2030 = add_name_phonetics(census_2030)\n",
    "census_2030 = add_address_phonetics(census_2030)\n",
    "\n",
    "geobase_reference_file = add_address_phonetics(geobase_reference_file)\n",
    "\n",
    "name_dob_reference_file = add_name_phonetics(name_dob_reference_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7ff2faa-d6b4-41e5-bbcd-e73d7a95eddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Columns used to \"cut the database\": ZIP3 and a grouping of first and last initial\n",
    "def add_zip3(df):\n",
    "    return df.assign(zip3=lambda x: x.zipcode.str[:3])\n",
    "\n",
    "def add_first_last_initial_categories(df):\n",
    "    # Page 20 of the NORC report: \"Name-cuts are defined by combinations of the first characters of the first and last names. The twenty letter groupings\n",
    "    # for the first character are: A-or-blank, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, and U-Z.\"\n",
    "    initial_cut = lambda x: x.fillna('A').str[0].replace('A', 'A-or-blank').replace(['U', 'V', 'W', 'X', 'Y', 'Z'], 'U-Z')\n",
    "    return df.assign(first_initial_cut=lambda x: initial_cut(x.first_name), last_initial_cut=lambda x: initial_cut(x.last_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aac8af1-2d9f-4fb0-9b54-d0a8e49dc96c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "census_2030 = add_zip3(census_2030)\n",
    "census_2030 = add_first_last_initial_categories(census_2030)\n",
    "\n",
    "geobase_reference_file = add_zip3(geobase_reference_file)\n",
    "\n",
    "name_dob_reference_file = add_first_last_initial_categories(name_dob_reference_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e413173-dde2-4bdb-a2cf-f0c5ef38e9a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data, ready to link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4306cf4f-d636-4d0c-9b07-7b73627982d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>record_id_raw_input_file</th>\n",
       "      <th>household_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_initial</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "      <th>street_number</th>\n",
       "      <th>street_name</th>\n",
       "      <th>unit_number</th>\n",
       "      <th>...</th>\n",
       "      <th>first_name_3</th>\n",
       "      <th>last_name_3</th>\n",
       "      <th>first_name_nysiis</th>\n",
       "      <th>first_name_reverse_soundex</th>\n",
       "      <th>last_name_nysiis</th>\n",
       "      <th>last_name_reverse_soundex</th>\n",
       "      <th>street_name_soundex</th>\n",
       "      <th>zip3</th>\n",
       "      <th>first_initial_cut</th>\n",
       "      <th>last_initial_cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>census_2030_preprocessed_0</td>\n",
       "      <td>simulated_census_2030_0</td>\n",
       "      <td>0_8033</td>\n",
       "      <td>Gerald</td>\n",
       "      <td>R</td>\n",
       "      <td>Allen</td>\n",
       "      <td>86</td>\n",
       "      <td>1130</td>\n",
       "      <td>MALLORY LN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Ger</td>\n",
       "      <td>All</td>\n",
       "      <td>GARALD</td>\n",
       "      <td>D462</td>\n",
       "      <td>ALAN</td>\n",
       "      <td>N400</td>\n",
       "      <td>M464</td>\n",
       "      <td>000</td>\n",
       "      <td>G</td>\n",
       "      <td>A-or-blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>census_2030_preprocessed_1</td>\n",
       "      <td>simulated_census_2030_1</td>\n",
       "      <td>0_1066</td>\n",
       "      <td>April</td>\n",
       "      <td>S</td>\n",
       "      <td>Hayden</td>\n",
       "      <td>33</td>\n",
       "      <td>32597</td>\n",
       "      <td>DELACORTE DR</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Hay</td>\n",
       "      <td>APRAL</td>\n",
       "      <td>L610</td>\n",
       "      <td>HAYDAN</td>\n",
       "      <td>N300</td>\n",
       "      <td>D426</td>\n",
       "      <td>000</td>\n",
       "      <td>A-or-blank</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>census_2030_preprocessed_2</td>\n",
       "      <td>simulated_census_2030_2</td>\n",
       "      <td>0_1066</td>\n",
       "      <td>Loretta</td>\n",
       "      <td>T</td>\n",
       "      <td>Lowe</td>\n",
       "      <td>71</td>\n",
       "      <td>32597</td>\n",
       "      <td>DELACORTE DR</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Lor</td>\n",
       "      <td>Low</td>\n",
       "      <td>LARAT</td>\n",
       "      <td>A364</td>\n",
       "      <td>LAO</td>\n",
       "      <td>E400</td>\n",
       "      <td>D426</td>\n",
       "      <td>000</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>census_2030_preprocessed_3</td>\n",
       "      <td>simulated_census_2030_3</td>\n",
       "      <td>0_2514</td>\n",
       "      <td>Sandra</td>\n",
       "      <td>A</td>\n",
       "      <td>Sorrentino</td>\n",
       "      <td>75</td>\n",
       "      <td>4458</td>\n",
       "      <td>WIBDSOR PL</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>San</td>\n",
       "      <td>Sor</td>\n",
       "      <td>SANDR</td>\n",
       "      <td>A635</td>\n",
       "      <td>SARANTAN</td>\n",
       "      <td>O535</td>\n",
       "      <td>W132</td>\n",
       "      <td>000</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>census_2030_preprocessed_4</td>\n",
       "      <td>simulated_census_2030_4</td>\n",
       "      <td>0_5627</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>S</td>\n",
       "      <td>Baker</td>\n",
       "      <td>44</td>\n",
       "      <td>None</td>\n",
       "      <td>WINDING TRAIL RD</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Bak</td>\n",
       "      <td>BABY</td>\n",
       "      <td>Y110</td>\n",
       "      <td>BACAR</td>\n",
       "      <td>R210</td>\n",
       "      <td>W535</td>\n",
       "      <td>000</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11028</th>\n",
       "      <td>census_2030_preprocessed_11028</td>\n",
       "      <td>simulated_census_2030_11028</td>\n",
       "      <td>0_10693</td>\n",
       "      <td>Zechariah</td>\n",
       "      <td>C</td>\n",
       "      <td>Deshpande</td>\n",
       "      <td>0</td>\n",
       "      <td>1534</td>\n",
       "      <td>BENTLEY DR</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Zec</td>\n",
       "      <td>Des</td>\n",
       "      <td>ZACAR</td>\n",
       "      <td>H622</td>\n",
       "      <td>DASPAND</td>\n",
       "      <td>E351</td>\n",
       "      <td>B534</td>\n",
       "      <td>000</td>\n",
       "      <td>U-Z</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11029</th>\n",
       "      <td>census_2030_preprocessed_11029</td>\n",
       "      <td>simulated_census_2030_3803</td>\n",
       "      <td>0_492</td>\n",
       "      <td>Charles</td>\n",
       "      <td>P</td>\n",
       "      <td>Foreman</td>\n",
       "      <td>64</td>\n",
       "      <td>224</td>\n",
       "      <td>N SANFORD ST</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Cha</td>\n",
       "      <td>For</td>\n",
       "      <td>CARL</td>\n",
       "      <td>S462</td>\n",
       "      <td>FARANAN</td>\n",
       "      <td>N561</td>\n",
       "      <td>N251</td>\n",
       "      <td>000</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030</th>\n",
       "      <td>census_2030_preprocessed_11030</td>\n",
       "      <td>simulated_census_2030_6806</td>\n",
       "      <td>0_11238</td>\n",
       "      <td>William</td>\n",
       "      <td>S</td>\n",
       "      <td>Vick</td>\n",
       "      <td>59</td>\n",
       "      <td>829</td>\n",
       "      <td>BERKELEY AVE</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Wil</td>\n",
       "      <td>Vic</td>\n",
       "      <td>WALAN</td>\n",
       "      <td>M400</td>\n",
       "      <td>VAC</td>\n",
       "      <td>K100</td>\n",
       "      <td>B624</td>\n",
       "      <td>000</td>\n",
       "      <td>U-Z</td>\n",
       "      <td>U-Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11031</th>\n",
       "      <td>census_2030_preprocessed_11031</td>\n",
       "      <td>simulated_census_2030_7705</td>\n",
       "      <td>0_6764</td>\n",
       "      <td>Charles</td>\n",
       "      <td>P</td>\n",
       "      <td>Qusmus</td>\n",
       "      <td>63</td>\n",
       "      <td>6801</td>\n",
       "      <td>REDWOOD TERRACE</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Cha</td>\n",
       "      <td>Qus</td>\n",
       "      <td>CARL</td>\n",
       "      <td>S462</td>\n",
       "      <td>QASN</td>\n",
       "      <td>S522</td>\n",
       "      <td>R333</td>\n",
       "      <td>000</td>\n",
       "      <td>C</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11032</th>\n",
       "      <td>census_2030_preprocessed_11032</td>\n",
       "      <td>simulated_census_2030_8840</td>\n",
       "      <td>0_11838</td>\n",
       "      <td>William</td>\n",
       "      <td>H</td>\n",
       "      <td>Tipton</td>\n",
       "      <td>29</td>\n",
       "      <td>148</td>\n",
       "      <td>ANGLIN DR</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Wil</td>\n",
       "      <td>Tip</td>\n",
       "      <td>WALAN</td>\n",
       "      <td>M400</td>\n",
       "      <td>TAPTAN</td>\n",
       "      <td>N313</td>\n",
       "      <td>A524</td>\n",
       "      <td>000</td>\n",
       "      <td>U-Z</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11030 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            record_id     record_id_raw_input_file  \\\n",
       "0          census_2030_preprocessed_0      simulated_census_2030_0   \n",
       "1          census_2030_preprocessed_1      simulated_census_2030_1   \n",
       "2          census_2030_preprocessed_2      simulated_census_2030_2   \n",
       "3          census_2030_preprocessed_3      simulated_census_2030_3   \n",
       "4          census_2030_preprocessed_4      simulated_census_2030_4   \n",
       "...                               ...                          ...   \n",
       "11028  census_2030_preprocessed_11028  simulated_census_2030_11028   \n",
       "11029  census_2030_preprocessed_11029   simulated_census_2030_3803   \n",
       "11030  census_2030_preprocessed_11030   simulated_census_2030_6806   \n",
       "11031  census_2030_preprocessed_11031   simulated_census_2030_7705   \n",
       "11032  census_2030_preprocessed_11032   simulated_census_2030_8840   \n",
       "\n",
       "      household_id first_name middle_initial   last_name age street_number  \\\n",
       "0           0_8033     Gerald              R       Allen  86          1130   \n",
       "1           0_1066      April              S      Hayden  33         32597   \n",
       "2           0_1066    Loretta              T        Lowe  71         32597   \n",
       "3           0_2514     Sandra              A  Sorrentino  75          4458   \n",
       "4           0_5627      Bobby              S       Baker  44          None   \n",
       "...            ...        ...            ...         ...  ..           ...   \n",
       "11028      0_10693  Zechariah              C   Deshpande   0          1534   \n",
       "11029        0_492    Charles              P     Foreman  64           224   \n",
       "11030      0_11238    William              S        Vick  59           829   \n",
       "11031       0_6764    Charles              P      Qusmus  63          6801   \n",
       "11032      0_11838    William              H      Tipton  29           148   \n",
       "\n",
       "            street_name unit_number  ... first_name_3 last_name_3  \\\n",
       "0            MALLORY LN        None  ...          Ger         All   \n",
       "1          DELACORTE DR        None  ...          Apr         Hay   \n",
       "2          DELACORTE DR        None  ...          Lor         Low   \n",
       "3            WIBDSOR PL        None  ...          San         Sor   \n",
       "4      WINDING TRAIL RD        None  ...          Bob         Bak   \n",
       "...                 ...         ...  ...          ...         ...   \n",
       "11028        BENTLEY DR        None  ...          Zec         Des   \n",
       "11029      N SANFORD ST        None  ...          Cha         For   \n",
       "11030      BERKELEY AVE        None  ...          Wil         Vic   \n",
       "11031   REDWOOD TERRACE        None  ...          Cha         Qus   \n",
       "11032         ANGLIN DR        None  ...          Wil         Tip   \n",
       "\n",
       "      first_name_nysiis first_name_reverse_soundex last_name_nysiis  \\\n",
       "0                GARALD                       D462             ALAN   \n",
       "1                 APRAL                       L610           HAYDAN   \n",
       "2                 LARAT                       A364              LAO   \n",
       "3                 SANDR                       A635         SARANTAN   \n",
       "4                  BABY                       Y110            BACAR   \n",
       "...                 ...                        ...              ...   \n",
       "11028             ZACAR                       H622          DASPAND   \n",
       "11029              CARL                       S462          FARANAN   \n",
       "11030             WALAN                       M400              VAC   \n",
       "11031              CARL                       S462             QASN   \n",
       "11032             WALAN                       M400           TAPTAN   \n",
       "\n",
       "      last_name_reverse_soundex street_name_soundex  zip3  first_initial_cut  \\\n",
       "0                          N400                M464   000                  G   \n",
       "1                          N300                D426   000         A-or-blank   \n",
       "2                          E400                D426   000                  L   \n",
       "3                          O535                W132   000                  S   \n",
       "4                          R210                W535   000                  B   \n",
       "...                         ...                 ...   ...                ...   \n",
       "11028                      E351                B534   000                U-Z   \n",
       "11029                      N561                N251   000                  C   \n",
       "11030                      K100                B624   000                U-Z   \n",
       "11031                      S522                R333   000                  C   \n",
       "11032                      N313                A524   000                U-Z   \n",
       "\n",
       "       last_initial_cut  \n",
       "0            A-or-blank  \n",
       "1                     H  \n",
       "2                     L  \n",
       "3                     S  \n",
       "4                     B  \n",
       "...                 ...  \n",
       "11028                 D  \n",
       "11029                 F  \n",
       "11030               U-Z  \n",
       "11031                 Q  \n",
       "11032                 T  \n",
       "\n",
       "[11030 rows x 38 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_2030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2361fef9-e338-4c81-934d-075dafdbd432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>ssn</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>street_number</th>\n",
       "      <th>street_name</th>\n",
       "      <th>unit_number</th>\n",
       "      <th>po_box</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>last_name_12</th>\n",
       "      <th>middle_initial</th>\n",
       "      <th>first_name_1</th>\n",
       "      <th>last_name_1</th>\n",
       "      <th>first_name_2</th>\n",
       "      <th>last_name_2</th>\n",
       "      <th>first_name_3</th>\n",
       "      <th>last_name_3</th>\n",
       "      <th>street_name_soundex</th>\n",
       "      <th>zip3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulated_geobase_reference_file_0</td>\n",
       "      <td>685-77-0916</td>\n",
       "      <td>Betty</td>\n",
       "      <td>Audrey</td>\n",
       "      <td>Keel</td>\n",
       "      <td>47461</td>\n",
       "      <td>W ROXBURY DR</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ANYTOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>Keel</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>K</td>\n",
       "      <td>Be</td>\n",
       "      <td>Ke</td>\n",
       "      <td>Bet</td>\n",
       "      <td>Kee</td>\n",
       "      <td>W621</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simulated_geobase_reference_file_1</td>\n",
       "      <td>765-44-4521</td>\n",
       "      <td>Ethep</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>Collier</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Collier</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>Et</td>\n",
       "      <td>Co</td>\n",
       "      <td>Eth</td>\n",
       "      <td>Col</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simulated_geobase_reference_file_2</td>\n",
       "      <td>765-44-4521</td>\n",
       "      <td>Ethep</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>Collier</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Collier</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>Et</td>\n",
       "      <td>Co</td>\n",
       "      <td>Eth</td>\n",
       "      <td>Col</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simulated_geobase_reference_file_3</td>\n",
       "      <td>726-57-2168</td>\n",
       "      <td>Josephine</td>\n",
       "      <td>Margaret</td>\n",
       "      <td>Babbie</td>\n",
       "      <td>3743</td>\n",
       "      <td>MESA VERDE ST</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ANYTOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>Babbie</td>\n",
       "      <td>M</td>\n",
       "      <td>J</td>\n",
       "      <td>B</td>\n",
       "      <td>Jo</td>\n",
       "      <td>Ba</td>\n",
       "      <td>Jos</td>\n",
       "      <td>Bab</td>\n",
       "      <td>M216</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simulated_geobase_reference_file_4</td>\n",
       "      <td>726-57-2168</td>\n",
       "      <td>Josephine</td>\n",
       "      <td>Margaret</td>\n",
       "      <td>Babbie</td>\n",
       "      <td>3743</td>\n",
       "      <td>MESA VERDE ST</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Babbie</td>\n",
       "      <td>M</td>\n",
       "      <td>J</td>\n",
       "      <td>B</td>\n",
       "      <td>Jo</td>\n",
       "      <td>Ba</td>\n",
       "      <td>Jos</td>\n",
       "      <td>Bab</td>\n",
       "      <td>M216</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32820</th>\n",
       "      <td>simulated_geobase_reference_file_32820</td>\n",
       "      <td>939-53-1702</td>\n",
       "      <td>Josiah</td>\n",
       "      <td>L</td>\n",
       "      <td>Mcmiller</td>\n",
       "      <td>2904</td>\n",
       "      <td>YACHT CLUB PT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ANYTOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>Mcmiller</td>\n",
       "      <td>L</td>\n",
       "      <td>J</td>\n",
       "      <td>M</td>\n",
       "      <td>Jo</td>\n",
       "      <td>Mc</td>\n",
       "      <td>Jos</td>\n",
       "      <td>Mcm</td>\n",
       "      <td>Y232</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32821</th>\n",
       "      <td>simulated_geobase_reference_file_32821</td>\n",
       "      <td>939-53-1702</td>\n",
       "      <td>Josiah</td>\n",
       "      <td>L</td>\n",
       "      <td>Mcmiller</td>\n",
       "      <td>W14066</td>\n",
       "      <td>E VALENCIA RD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ANYTOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>Mcmiller</td>\n",
       "      <td>L</td>\n",
       "      <td>J</td>\n",
       "      <td>M</td>\n",
       "      <td>Jo</td>\n",
       "      <td>Mc</td>\n",
       "      <td>Jos</td>\n",
       "      <td>Mcm</td>\n",
       "      <td>E145</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32822</th>\n",
       "      <td>simulated_geobase_reference_file_32822</td>\n",
       "      <td>939-53-1702</td>\n",
       "      <td>Josiah</td>\n",
       "      <td>L</td>\n",
       "      <td>Mcmiller</td>\n",
       "      <td>W14066</td>\n",
       "      <td>E VALENCIA RD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ANYTOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>Mcmiller</td>\n",
       "      <td>L</td>\n",
       "      <td>J</td>\n",
       "      <td>M</td>\n",
       "      <td>Jo</td>\n",
       "      <td>Mc</td>\n",
       "      <td>Jos</td>\n",
       "      <td>Mcm</td>\n",
       "      <td>E145</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32823</th>\n",
       "      <td>simulated_geobase_reference_file_32823</td>\n",
       "      <td>993-56-2286</td>\n",
       "      <td>Larisa</td>\n",
       "      <td>A</td>\n",
       "      <td>Beilfuss</td>\n",
       "      <td>1411</td>\n",
       "      <td>W 80TH ST</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ANYTOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>Beilfuss</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>B</td>\n",
       "      <td>La</td>\n",
       "      <td>Be</td>\n",
       "      <td>Lar</td>\n",
       "      <td>Bei</td>\n",
       "      <td>W323</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32824</th>\n",
       "      <td>simulated_geobase_reference_file_32824</td>\n",
       "      <td>997-51-7349</td>\n",
       "      <td>Brooks</td>\n",
       "      <td>None</td>\n",
       "      <td>Cuellar</td>\n",
       "      <td>116</td>\n",
       "      <td>WAKEMA RD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ANYTOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>Cuellar</td>\n",
       "      <td>None</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>Br</td>\n",
       "      <td>Cu</td>\n",
       "      <td>Bro</td>\n",
       "      <td>Cue</td>\n",
       "      <td>W256</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32825 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    record_id          ssn first_name  \\\n",
       "0          simulated_geobase_reference_file_0  685-77-0916      Betty   \n",
       "1          simulated_geobase_reference_file_1  765-44-4521      Ethep   \n",
       "2          simulated_geobase_reference_file_2  765-44-4521      Ethep   \n",
       "3          simulated_geobase_reference_file_3  726-57-2168  Josephine   \n",
       "4          simulated_geobase_reference_file_4  726-57-2168  Josephine   \n",
       "...                                       ...          ...        ...   \n",
       "32820  simulated_geobase_reference_file_32820  939-53-1702     Josiah   \n",
       "32821  simulated_geobase_reference_file_32821  939-53-1702     Josiah   \n",
       "32822  simulated_geobase_reference_file_32822  939-53-1702     Josiah   \n",
       "32823  simulated_geobase_reference_file_32823  993-56-2286     Larisa   \n",
       "32824  simulated_geobase_reference_file_32824  997-51-7349     Brooks   \n",
       "\n",
       "      middle_name last_name street_number    street_name unit_number po_box  \\\n",
       "0          Audrey      Keel         47461   W ROXBURY DR        None   None   \n",
       "1           Nancy   Collier          None           None        None   None   \n",
       "2           Nancy   Collier          None           None        None   None   \n",
       "3        Margaret    Babbie          3743  MESA VERDE ST        None   None   \n",
       "4        Margaret    Babbie          3743  MESA VERDE ST        None   None   \n",
       "...           ...       ...           ...            ...         ...    ...   \n",
       "32820           L  Mcmiller          2904  YACHT CLUB PT        None   None   \n",
       "32821           L  Mcmiller        W14066  E VALENCIA RD        None   None   \n",
       "32822           L  Mcmiller        W14066  E VALENCIA RD        None   None   \n",
       "32823           A  Beilfuss          1411      W 80TH ST        None   None   \n",
       "32824        None   Cuellar           116      WAKEMA RD        None   None   \n",
       "\n",
       "          city  ... last_name_12 middle_initial first_name_1  last_name_1  \\\n",
       "0      ANYTOWN  ...         Keel              A            B            K   \n",
       "1         None  ...      Collier              N            E            C   \n",
       "2         None  ...      Collier              N            E            C   \n",
       "3      ANYTOWN  ...       Babbie              M            J            B   \n",
       "4         None  ...       Babbie              M            J            B   \n",
       "...        ...  ...          ...            ...          ...          ...   \n",
       "32820  ANYTOWN  ...     Mcmiller              L            J            M   \n",
       "32821  ANYTOWN  ...     Mcmiller              L            J            M   \n",
       "32822  ANYTOWN  ...     Mcmiller              L            J            M   \n",
       "32823  ANYTOWN  ...     Beilfuss              A            L            B   \n",
       "32824  ANYTOWN  ...      Cuellar           None            B            C   \n",
       "\n",
       "       first_name_2  last_name_2 first_name_3 last_name_3 street_name_soundex  \\\n",
       "0                Be           Ke          Bet         Kee                W621   \n",
       "1                Et           Co          Eth         Col                 NaN   \n",
       "2                Et           Co          Eth         Col                 NaN   \n",
       "3                Jo           Ba          Jos         Bab                M216   \n",
       "4                Jo           Ba          Jos         Bab                M216   \n",
       "...             ...          ...          ...         ...                 ...   \n",
       "32820            Jo           Mc          Jos         Mcm                Y232   \n",
       "32821            Jo           Mc          Jos         Mcm                E145   \n",
       "32822            Jo           Mc          Jos         Mcm                E145   \n",
       "32823            La           Be          Lar         Bei                W323   \n",
       "32824            Br           Cu          Bro         Cue                W256   \n",
       "\n",
       "       zip3  \n",
       "0       000  \n",
       "1      None  \n",
       "2      None  \n",
       "3       000  \n",
       "4       000  \n",
       "...     ...  \n",
       "32820   000  \n",
       "32821   000  \n",
       "32822   000  \n",
       "32823   000  \n",
       "32824   000  \n",
       "\n",
       "[32825 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geobase_reference_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cebf9174-67d5-47e7-a072-5b2998faf57c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>ssn</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>pik</th>\n",
       "      <th>month_of_birth</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>day_of_birth</th>\n",
       "      <th>first_name_15</th>\n",
       "      <th>...</th>\n",
       "      <th>first_name_2</th>\n",
       "      <th>last_name_2</th>\n",
       "      <th>first_name_3</th>\n",
       "      <th>last_name_3</th>\n",
       "      <th>first_name_nysiis</th>\n",
       "      <th>first_name_reverse_soundex</th>\n",
       "      <th>last_name_nysiis</th>\n",
       "      <th>last_name_reverse_soundex</th>\n",
       "      <th>first_initial_cut</th>\n",
       "      <th>last_initial_cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulated_name_dob_reference_file_0</td>\n",
       "      <td>685-77-0916</td>\n",
       "      <td>Betty</td>\n",
       "      <td>Audrey</td>\n",
       "      <td>Keel</td>\n",
       "      <td>105906</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Betty</td>\n",
       "      <td>...</td>\n",
       "      <td>Be</td>\n",
       "      <td>Ke</td>\n",
       "      <td>Bet</td>\n",
       "      <td>Kee</td>\n",
       "      <td>BATY</td>\n",
       "      <td>Y310</td>\n",
       "      <td>CAL</td>\n",
       "      <td>L200</td>\n",
       "      <td>B</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simulated_name_dob_reference_file_1</td>\n",
       "      <td>765-44-4521</td>\n",
       "      <td>Ethep</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>Collier</td>\n",
       "      <td>104653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ethep</td>\n",
       "      <td>...</td>\n",
       "      <td>Et</td>\n",
       "      <td>Co</td>\n",
       "      <td>Eth</td>\n",
       "      <td>Col</td>\n",
       "      <td>ETAP</td>\n",
       "      <td>P300</td>\n",
       "      <td>CALAR</td>\n",
       "      <td>R420</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simulated_name_dob_reference_file_2</td>\n",
       "      <td>765-44-4521</td>\n",
       "      <td>Ethep</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>Collier</td>\n",
       "      <td>104653</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Ethep</td>\n",
       "      <td>...</td>\n",
       "      <td>Et</td>\n",
       "      <td>Co</td>\n",
       "      <td>Eth</td>\n",
       "      <td>Col</td>\n",
       "      <td>ETAP</td>\n",
       "      <td>P300</td>\n",
       "      <td>CALAR</td>\n",
       "      <td>R420</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simulated_name_dob_reference_file_3</td>\n",
       "      <td>726-57-2168</td>\n",
       "      <td>Josephine</td>\n",
       "      <td>Margaret</td>\n",
       "      <td>Babbie</td>\n",
       "      <td>106223</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Josephine</td>\n",
       "      <td>...</td>\n",
       "      <td>Jo</td>\n",
       "      <td>Ba</td>\n",
       "      <td>Jos</td>\n",
       "      <td>Bab</td>\n",
       "      <td>JASAFAN</td>\n",
       "      <td>E512</td>\n",
       "      <td>BABY</td>\n",
       "      <td>E110</td>\n",
       "      <td>J</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simulated_name_dob_reference_file_4</td>\n",
       "      <td>365-44-3027</td>\n",
       "      <td>Betty</td>\n",
       "      <td>Mary</td>\n",
       "      <td>None</td>\n",
       "      <td>107896</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Betty</td>\n",
       "      <td>...</td>\n",
       "      <td>Be</td>\n",
       "      <td>None</td>\n",
       "      <td>Bet</td>\n",
       "      <td>None</td>\n",
       "      <td>BATY</td>\n",
       "      <td>Y310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>A-or-blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19870</th>\n",
       "      <td>simulated_name_dob_reference_file_19870</td>\n",
       "      <td>977-84-6791</td>\n",
       "      <td>Liam</td>\n",
       "      <td>L</td>\n",
       "      <td>Wheatley</td>\n",
       "      <td>108816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liam</td>\n",
       "      <td>...</td>\n",
       "      <td>Li</td>\n",
       "      <td>Wh</td>\n",
       "      <td>Lia</td>\n",
       "      <td>Whe</td>\n",
       "      <td>LAN</td>\n",
       "      <td>M400</td>\n",
       "      <td>WATLY</td>\n",
       "      <td>Y430</td>\n",
       "      <td>L</td>\n",
       "      <td>U-Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19871</th>\n",
       "      <td>simulated_name_dob_reference_file_19871</td>\n",
       "      <td>997-95-0405</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>D</td>\n",
       "      <td>Dellinger</td>\n",
       "      <td>108817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>...</td>\n",
       "      <td>Jo</td>\n",
       "      <td>De</td>\n",
       "      <td>Jos</td>\n",
       "      <td>Del</td>\n",
       "      <td>JASAF</td>\n",
       "      <td>H122</td>\n",
       "      <td>DALANGAR</td>\n",
       "      <td>R254</td>\n",
       "      <td>J</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19872</th>\n",
       "      <td>simulated_name_dob_reference_file_19872</td>\n",
       "      <td>939-53-1702</td>\n",
       "      <td>Josiah</td>\n",
       "      <td>L</td>\n",
       "      <td>Mcmiller</td>\n",
       "      <td>108818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Josiah</td>\n",
       "      <td>...</td>\n",
       "      <td>Jo</td>\n",
       "      <td>Mc</td>\n",
       "      <td>Jos</td>\n",
       "      <td>Mcm</td>\n",
       "      <td>JAS</td>\n",
       "      <td>H220</td>\n",
       "      <td>MCNALAR</td>\n",
       "      <td>R452</td>\n",
       "      <td>J</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19873</th>\n",
       "      <td>simulated_name_dob_reference_file_19873</td>\n",
       "      <td>993-56-2286</td>\n",
       "      <td>Larisa</td>\n",
       "      <td>A</td>\n",
       "      <td>Beilfuss</td>\n",
       "      <td>108819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Larisa</td>\n",
       "      <td>...</td>\n",
       "      <td>La</td>\n",
       "      <td>Be</td>\n",
       "      <td>Lar</td>\n",
       "      <td>Bei</td>\n",
       "      <td>LARAS</td>\n",
       "      <td>A264</td>\n",
       "      <td>BALF</td>\n",
       "      <td>S141</td>\n",
       "      <td>L</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19874</th>\n",
       "      <td>simulated_name_dob_reference_file_19874</td>\n",
       "      <td>997-51-7349</td>\n",
       "      <td>Brooks</td>\n",
       "      <td>None</td>\n",
       "      <td>Cuellar</td>\n",
       "      <td>108820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brooks</td>\n",
       "      <td>...</td>\n",
       "      <td>Br</td>\n",
       "      <td>Cu</td>\n",
       "      <td>Bro</td>\n",
       "      <td>Cue</td>\n",
       "      <td>BRAC</td>\n",
       "      <td>S610</td>\n",
       "      <td>CALAR</td>\n",
       "      <td>R420</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19875 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     record_id          ssn first_name  \\\n",
       "0          simulated_name_dob_reference_file_0  685-77-0916      Betty   \n",
       "1          simulated_name_dob_reference_file_1  765-44-4521      Ethep   \n",
       "2          simulated_name_dob_reference_file_2  765-44-4521      Ethep   \n",
       "3          simulated_name_dob_reference_file_3  726-57-2168  Josephine   \n",
       "4          simulated_name_dob_reference_file_4  365-44-3027      Betty   \n",
       "...                                        ...          ...        ...   \n",
       "19870  simulated_name_dob_reference_file_19870  977-84-6791       Liam   \n",
       "19871  simulated_name_dob_reference_file_19871  997-95-0405     Joseph   \n",
       "19872  simulated_name_dob_reference_file_19872  939-53-1702     Josiah   \n",
       "19873  simulated_name_dob_reference_file_19873  993-56-2286     Larisa   \n",
       "19874  simulated_name_dob_reference_file_19874  997-51-7349     Brooks   \n",
       "\n",
       "      middle_name  last_name     pik  month_of_birth  year_of_birth  \\\n",
       "0          Audrey       Keel  105906            12.0         1922.0   \n",
       "1           Nancy    Collier  104653             NaN            NaN   \n",
       "2           Nancy    Collier  104653             2.0         1923.0   \n",
       "3        Margaret     Babbie  106223             7.0         1923.0   \n",
       "4            Mary       None  107896             8.0         1923.0   \n",
       "...           ...        ...     ...             ...            ...   \n",
       "19870           L   Wheatley  108816             NaN            NaN   \n",
       "19871           D  Dellinger  108817             NaN            NaN   \n",
       "19872           L   Mcmiller  108818             NaN            NaN   \n",
       "19873           A   Beilfuss  108819             NaN            NaN   \n",
       "19874        None    Cuellar  108820             NaN            NaN   \n",
       "\n",
       "       day_of_birth first_name_15  ... first_name_2 last_name_2 first_name_3  \\\n",
       "0               5.0         Betty  ...           Be          Ke          Bet   \n",
       "1               NaN         Ethep  ...           Et          Co          Eth   \n",
       "2              13.0         Ethep  ...           Et          Co          Eth   \n",
       "3              28.0     Josephine  ...           Jo          Ba          Jos   \n",
       "4               9.0         Betty  ...           Be        None          Bet   \n",
       "...             ...           ...  ...          ...         ...          ...   \n",
       "19870           NaN          Liam  ...           Li          Wh          Lia   \n",
       "19871           NaN        Joseph  ...           Jo          De          Jos   \n",
       "19872           NaN        Josiah  ...           Jo          Mc          Jos   \n",
       "19873           NaN        Larisa  ...           La          Be          Lar   \n",
       "19874           NaN        Brooks  ...           Br          Cu          Bro   \n",
       "\n",
       "      last_name_3 first_name_nysiis first_name_reverse_soundex  \\\n",
       "0             Kee              BATY                       Y310   \n",
       "1             Col              ETAP                       P300   \n",
       "2             Col              ETAP                       P300   \n",
       "3             Bab           JASAFAN                       E512   \n",
       "4            None              BATY                       Y310   \n",
       "...           ...               ...                        ...   \n",
       "19870         Whe               LAN                       M400   \n",
       "19871         Del             JASAF                       H122   \n",
       "19872         Mcm               JAS                       H220   \n",
       "19873         Bei             LARAS                       A264   \n",
       "19874         Cue              BRAC                       S610   \n",
       "\n",
       "      last_name_nysiis last_name_reverse_soundex first_initial_cut  \\\n",
       "0                  CAL                      L200                 B   \n",
       "1                CALAR                      R420                 E   \n",
       "2                CALAR                      R420                 E   \n",
       "3                 BABY                      E110                 J   \n",
       "4                  NaN                       NaN                 B   \n",
       "...                ...                       ...               ...   \n",
       "19870            WATLY                      Y430                 L   \n",
       "19871         DALANGAR                      R254                 J   \n",
       "19872          MCNALAR                      R452                 J   \n",
       "19873             BALF                      S141                 L   \n",
       "19874            CALAR                      R420                 B   \n",
       "\n",
       "      last_initial_cut  \n",
       "0                    K  \n",
       "1                    C  \n",
       "2                    C  \n",
       "3                    B  \n",
       "4           A-or-blank  \n",
       "...                ...  \n",
       "19870              U-Z  \n",
       "19871                D  \n",
       "19872                M  \n",
       "19873                B  \n",
       "19874                C  \n",
       "\n",
       "[19875 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dob_reference_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a115b7-6215-4bcf-8444-ef2223040a02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Emulate Multi-Match with fastLink\n",
    "\n",
    "Wagner and Layne, p. 8:\n",
    "\n",
    "> The PVS employs its probabilistic record linkage software, Multi-Match (Wagner\n",
    "2012), as an integral part of the PVS.\n",
    "\n",
    "Wagner and Layne, p. 12:\n",
    "\n",
    "> PVS uses the same Multi-Match engine for each probabilistic search type. For each\n",
    "search module the analyst defines a parameter file, which is passed to Multi-Match. The\n",
    "parameter file includes threshold value(s) for the number of passes, blocking keys, and\n",
    "within each pass, the match variables, match comparison type, and matching weights...\n",
    ">\n",
    "> Records must first match exactly on the blocking keys before any comparisons\n",
    "between the match variables are attempted. Each match variable is given an\n",
    "m and\n",
    "u\n",
    "probability, which is translated by MultiMatch as agreement and disagreement weights.\n",
    "The sum of all match variable comparison weights for a record pair is the composite\n",
    "weight. All record pairs with a composite weight greater than or equal to the threshold\n",
    "set in the parameter file are linked, and the records from the incoming file for these\n",
    "linked cases are excluded from all remaining passes. All Numident records are always\n",
    "available for linking in every pass. Any record missing data for any of the blocking fields\n",
    "for a pass skips that pass and moves to the next pass.\n",
    "\n",
    "[fastLink](https://github.com/kosukeimai/fastLink) is similar to Multi-Match\n",
    "in that both are based on the Fellegi-Sunter approach to record linkage.\n",
    "However, it does not include blocking, and using the recommended approach of calling\n",
    "it separately on each block\n",
    "[does not perform well for very small and numerous blocks](https://github.com/kosukeimai/fastLink/issues/73#issuecomment-1672077417).\n",
    "\n",
    "Given these differences, it isn't currently possible to emulate the PVS cascade with fastLink.\n",
    "Instead, we do a single blocking pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a52fa1a-85ca-4a5a-a978-08e43c5b9eb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Estimate parameters\n",
    "\n",
    "In Multi-Match parameters are not directly estimated from the data.\n",
    "They are primarily set manually by analysts, with a different set of parameter files\n",
    "maintained for each type of input file (e.g. survey, administrative).\n",
    "\n",
    "We estimate the parameters using the GeoBase Reference File,\n",
    "since it has all columns that are used for matching with any reference file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "200ff16b-6632-4eff-962b-aea4c0bf73b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "import os\n",
    "# Use R in the current conda environment\n",
    "os.environ[\"R_HOME\"] = str(pathlib.Path(sys.executable).parent.parent / 'lib/R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ebab08c-4bc0-4d68-81fa-5a689f4ed40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "pandas2ri.activate()\n",
    "\n",
    "fastLink = importr('fastLink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccd062da-9ae2-461d-a761-68124105e364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== \n",
      "fastLink(): Fast Probabilistic Record Linkage\n",
      "==================== \n",
      "\n",
      "If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\n",
      "Calculating matches for each variable.\n",
      "Getting counts for parameter estimation.\n",
      "    Parallelizing calculation using OpenMP. 3 threads out of 2 are used.\n",
      "Running the EM algorithm.\n",
      "CPU times: user 2min 32s, sys: 8.91 s, total: 2min 41s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# From the fastLink README:\n",
    "# ## Run the algorithm on the random samples\n",
    "# rs.out <- fastLink(\n",
    "#   dfA = dfA.s, dfB = dfB.s, \n",
    "#   varnames = c(\"firstname\", \"middlename\", \"lastname\", \"housenum\", \"streetname\", \"city\", \"birthyear\"),\n",
    "#   stringdist.match = c(\"firstname\", \"middlename\", \"lastname\", \"streetname\", \"city\"),\n",
    "#   partial.match = c(\"firstname\", \"lastname\", \"streetname\"),\n",
    "#   estimate.only = TRUE\n",
    "# )\n",
    "\n",
    "from rpy2 import robjects as ro\n",
    "\n",
    "COMPARISON_COLUMNS = [\"first_name\", \"middle_initial\", \"last_name\", \"day_of_birth\", \"month_of_birth\", \"year_of_birth\", \"geokey\"]\n",
    "\n",
    "prep_for_fastLink = lambda df, *args: df[COMPARISON_COLUMNS].astype(str).fillna(ro.NA_Character).reset_index().rename(columns={'index': 'python_index'})\n",
    "\n",
    "em_object = fastLink.fastLink(\n",
    "    dfA = prep_for_fastLink(geobase_reference_file),\n",
    "    dfB = prep_for_fastLink(census_2030),\n",
    "    varnames = ro.StrVector(COMPARISON_COLUMNS),\n",
    "    stringdist_match = ro.StrVector([\"first_name\", \"last_name\", \"geokey\"]),\n",
    "    partial_match = ro.StrVector([\"first_name\", \"last_name\", \"geokey\"]),\n",
    "    # Just run EM, don't link\n",
    "    estimate_only = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b9963e-73da-4b51-837d-d79deca7fecf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implement matching passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f437d4c7-b848-4c19-b29d-5f48d10ce911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "# Calculate this once to save time -- mapping from record_id to record_id_raw_input_file\n",
    "# There can be multiple records (with different record_id) for the same input file record\n",
    "# (record_id_raw_input_file) because of the handling of nicknames by creating extra records.\n",
    "record_id_raw_input_file_by_record_id = census_2030.set_index('record_id').record_id_raw_input_file\n",
    "\n",
    "all_piks = pd.concat([\n",
    "    name_dob_reference_file[[\"record_id\", \"pik\"]],\n",
    "    geobase_reference_file[[\"record_id\", \"pik\"]]\n",
    "], ignore_index=True).set_index(\"record_id\").pik\n",
    "\n",
    "dates_of_death = (\n",
    "    pd.read_parquet(f'{input_dir}/{data_to_use}/simulated_census_numident.parquet')\n",
    "        .set_index('pik')\n",
    "        .date_of_death\n",
    "        .pipe(lambda s: pd.to_datetime(s, format='%Y%m%d', errors='coerce'))\n",
    ")\n",
    "\n",
    "class PersonLinkageCascade:\n",
    "    def __init__(self):\n",
    "        # This dataframe will accumulate the PIKs to attach to the input file\n",
    "        self.confirmed_piks = pd.DataFrame(columns=[\"record_id_raw_input_file\", \"pik\"])\n",
    "        self.current_module = None\n",
    "\n",
    "    def start_module(self, *args, **kwargs):\n",
    "        assert self.current_module is None or self.current_module.confirmed\n",
    "        self.current_module = PersonLinkageModule(*args, **kwargs)\n",
    "\n",
    "    def run_matching_pass(self, *args, **kwargs):\n",
    "        self.current_module.run_matching_pass(*args, already_confirmed_piks=self.confirmed_piks, **kwargs)\n",
    "\n",
    "    def confirm_piks(self, *args, **kwargs):\n",
    "        # Make sure we are not about to confirm PIKs for any of the same files we have\n",
    "        # already PIKed\n",
    "        assert (\n",
    "            set(self.current_module.provisional_links.record_id_raw_input_file) &\n",
    "            set(self.confirmed_piks.record_id_raw_input_file)\n",
    "        ) == set()\n",
    "\n",
    "        newly_confirmed_piks = self.current_module.confirm_piks_from_provisional_links()\n",
    "\n",
    "        self.confirmed_piks = pd.concat([\n",
    "            self.confirmed_piks,\n",
    "            newly_confirmed_piks,\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        return self.confirmed_piks\n",
    "\n",
    "@dataclass\n",
    "class PersonLinkageModule:\n",
    "    name: str\n",
    "    reference_file: pd.DataFrame\n",
    "    reference_file_name: str\n",
    "    # cut_columns: list[str]\n",
    "    matching_columns: list[str]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.provisional_links = pd.DataFrame(columns=[\"record_id_census_2030\"])\n",
    "        self.confirmed = False\n",
    "\n",
    "    def run_matching_pass(\n",
    "        self,\n",
    "        pass_name,\n",
    "        probability_threshold=0.99,\n",
    "        input_data_transformation=lambda x: x,\n",
    "        already_confirmed_piks=pd.DataFrame(columns=[\"record_id_raw_input_file\"]),\n",
    "    ):\n",
    "        assert self.confirmed == False\n",
    "\n",
    "        print(f\"Running {pass_name} of {self.name}\")\n",
    "\n",
    "        census_to_match = (\n",
    "            census_2030[\n",
    "                # Only look for matches among records that have not received a confirmed PIK\n",
    "                ~census_2030.record_id_raw_input_file.isin(already_confirmed_piks.record_id_raw_input_file) &\n",
    "                # Only look for matches among records that have not received a provisional link\n",
    "                # NOTE: \"records\" here does not mean input file records -- a nickname record having\n",
    "                # a provisional link does not prevent a canonical name record from the same input record\n",
    "                # from continuing to match\n",
    "                ~census_2030.record_id.isin(self.provisional_links.record_id_census_2030)\n",
    "            ].pipe(input_data_transformation)\n",
    "        )\n",
    "        # census_2030_for_fastLink = prep_for_fastLink(census_to_match)\n",
    "        # reference_file_for_fastLink = prep_for_fastLink(self.reference_file, self.reference_file_name)\n",
    "        print(f\"Files to link are {len(census_to_match):,.0f} and {len(self.reference_file):,.0f} records\")\n",
    "\n",
    "        # fastLink is slow with blocking, as noted above\n",
    "        # We don't actually do any blocking here, but we do have a homegrown method for doing it\n",
    "        # fastLink's blocking (blockData) also doesn't support blocking on multiple columns at once(!),\n",
    "        # so we implement our own blocking\n",
    "        # Technically we could have done it with some hacky approach involving appending the columns,\n",
    "        # but fastLink still requires you to make a separate linking call for each block anyway\n",
    "        census_to_match['dummy_blocking_key'] = 1\n",
    "        self.reference_file['dummy_blocking_key'] = 1\n",
    "        # I experimented with blocking on the cut columns only as a compromise, but it was still too slow\n",
    "        blocking_cols = ['dummy_blocking_key'] # self.cut_columns\n",
    "        census_2030_blocks = census_to_match.groupby(blocking_cols, as_index=False)\n",
    "        reference_file_blocks = self.reference_file.groupby(blocking_cols, as_index=False)\n",
    "\n",
    "        print(f'{census_2030_blocks.ngroups} blocks')\n",
    "\n",
    "        varnames = ro.StrVector(COMPARISON_COLUMNS)\n",
    "        stringdist_match = ro.StrVector([\"first_name\", \"last_name\", \"geokey\"])\n",
    "        partial_match = ro.StrVector([\"first_name\", \"last_name\", \"geokey\"])\n",
    "\n",
    "        new_provisional_links = []\n",
    "        for index, (key, census_2030_block) in enumerate(census_2030_blocks):\n",
    "            try:\n",
    "                # Weirdly, there is an inconsistency between the keys you get when iterating and the ones\n",
    "                # you have to pass to get_group\n",
    "                if isinstance(key, tuple) and len(key) == 1:\n",
    "                    key = key[0]\n",
    "                reference_file_block = reference_file_blocks.get_group(key)\n",
    "            except KeyError:\n",
    "                # Nothing in the reference file for this block; so that implies there are no\n",
    "                # matches to find\n",
    "                continue\n",
    "\n",
    "            if len(reference_file_block) == 1:\n",
    "                # HACK -- fastLink seems to not work at all if dfB is only one row\n",
    "                reference_file_block = pd.concat([reference_file_block, pd.DataFrame(np.nan, index=[-1], columns=reference_file_block.columns)])\n",
    "\n",
    "            census_2030_block_for_fastLink = prep_for_fastLink(census_2030_block)\n",
    "            reference_file_block_for_fastLink = prep_for_fastLink(reference_file_block)\n",
    "            with (ro.default_converter + pandas2ri.converter).context():\n",
    "                conversion = ro.conversion.get_conversion()\n",
    "                census_2030_block_for_fastLink_r = conversion.py2rpy(census_2030_block_for_fastLink)\n",
    "                reference_file_block_for_fastLink_r = conversion.py2rpy(reference_file_block_for_fastLink)\n",
    "\n",
    "            fastLink_result = fastLink.fastLink(\n",
    "                dfA=census_2030_block_for_fastLink_r,\n",
    "                dfB=reference_file_block_for_fastLink_r,\n",
    "                varnames=varnames,\n",
    "                stringdist_match=stringdist_match,\n",
    "                partial_match=partial_match,\n",
    "                em_obj=em_object,\n",
    "                threshold_match=probability_threshold,\n",
    "            )\n",
    "\n",
    "            census_2030_matches_r_indices = fastLink_result.rx2('matches').rx2('inds.a')\n",
    "            reference_file_matches_r_indices = fastLink_result.rx2('matches').rx2('inds.b')\n",
    "\n",
    "            census_2030_matches = pd.Index(census_2030_block_for_fastLink_r.rx(census_2030_matches_r_indices, 'python_index'))\n",
    "            reference_file_matches = pd.Index(reference_file_block_for_fastLink_r.rx(reference_file_matches_r_indices, 'python_index'))\n",
    "\n",
    "            new_provisional_links.append(\n",
    "                census_2030_block.loc[census_2030_matches].reset_index(drop=True).add_suffix('_census_2030')\n",
    "                .join(\n",
    "                    reference_file_block.loc[reference_file_matches].reset_index(drop=True).add_suffix('_reference_file')\n",
    "                )\n",
    "                .join(\n",
    "                    pd.Series(fastLink_result.rx2('posterior'), name='match_probability')\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if len(new_provisional_links) > 0:\n",
    "            new_provisional_links = pd.concat(new_provisional_links, ignore_index=True)\n",
    "\n",
    "        if len(new_provisional_links) > 0:\n",
    "            new_provisional_links[\"record_id_raw_input_file\"] = (\n",
    "                new_provisional_links.record_id_census_2030.map(record_id_raw_input_file_by_record_id)\n",
    "            )\n",
    "\n",
    "            self.provisional_links = pd.concat([\n",
    "                self.provisional_links,\n",
    "                new_provisional_links.assign(module_name=self.name, pass_name=pass_name)\n",
    "            ], ignore_index=True)\n",
    "\n",
    "        still_eligible = (\n",
    "            (~census_2030.record_id_raw_input_file.isin(already_confirmed_piks.record_id_raw_input_file)) &\n",
    "            (~census_2030.record_id.isin(self.provisional_links.record_id_census_2030))\n",
    "        )\n",
    "        print(f'Matched {len(new_provisional_links)} records; {still_eligible.mean():.2%} still eligible to match')\n",
    "\n",
    "    def confirm_piks_from_provisional_links(self):\n",
    "        assert not self.confirmed\n",
    "\n",
    "        provisional_links = self.provisional_links\n",
    "        provisional_links[\"pik\"] = provisional_links.record_id_reference_file.map(all_piks)\n",
    "\n",
    "        # \"After the initial set of links is created in GeoSearch, a post-search program is run to determine\n",
    "        # which of the links are retained. A series of checks are performed: First the date of death\n",
    "        # information from the Numident is checked and links to deceased persons are dropped. Next a\n",
    "        # check is made for more than one SSN assigned to a source record. If more than one SSN is\n",
    "        # assigned, the best link is selected based on match weights. If no best SSN is determined, all SSNs\n",
    "        # assigned in the GeoSearch module are dropped and the input record cascades to the next\n",
    "        # module. A similar post-search program is run at the end of all search modules.\"\n",
    "        # - Layne et al. p. 5\n",
    "\n",
    "        # Drop links to deceased people\n",
    "        # NOTE: On p. 38 of Brown et al. (2023) it discusses at length the number of PVS matches to deceased\n",
    "        # people, which should not be possible based on this process.\n",
    "        # Even though this is more recent, I can't think of a reason why this check would have\n",
    "        # been *removed* from PVS -- can we chalk this up to something experimental they were doing for\n",
    "        # the AR Census in the 2023 report?\n",
    "        link_dates_of_death = provisional_links[\"pik\"].map(dates_of_death)\n",
    "        # Census day 2030\n",
    "        deceased_links = link_dates_of_death <= pd.to_datetime(\"2030-04-01\")\n",
    "        print(f'{deceased_links.sum()} input records linked to deceased people, dropping links')\n",
    "        provisional_links = provisional_links[~deceased_links]\n",
    "\n",
    "        # Check for multiple linkage to a single input file record\n",
    "        max_probability = provisional_links.groupby(\"record_id_raw_input_file\").match_probability.max()\n",
    "        piks_per_input_file = (\n",
    "            provisional_links.groupby(\"record_id_raw_input_file\")\n",
    "                .apply(lambda df: df[df.match_probability == max_probability[df.name]].pik.nunique())\n",
    "        )\n",
    "\n",
    "        multiple_piks = piks_per_input_file[piks_per_input_file > 1].index\n",
    "        print(f'{len(multiple_piks)} input records linked to multiple PIKs, dropping links')\n",
    "        provisional_links = (\n",
    "            provisional_links[~provisional_links.record_id_raw_input_file.isin(multiple_piks)]\n",
    "                .sort_values(\"match_probability\")\n",
    "                .groupby(\"record_id_raw_input_file\")\n",
    "                .last()\n",
    "                .reset_index()\n",
    "        )\n",
    "\n",
    "        assert (provisional_links.groupby(\"record_id_raw_input_file\").pik.nunique() == 1).all()\n",
    "\n",
    "        self.confirmed = True\n",
    "        self.provisional_links = None\n",
    "        \n",
    "        return (\n",
    "            provisional_links[[\n",
    "                \"record_id_raw_input_file\",\n",
    "                \"record_id_census_2030\",\n",
    "                \"record_id_reference_file\",\n",
    "                \"pik\",\n",
    "                \"module_name\",\n",
    "                \"pass_name\",\n",
    "                \"match_probability\",\n",
    "            ]]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f988466-eec7-4432-baf1-467868e4d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_linkage_cascade = PersonLinkageCascade()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0203571-b01f-477b-879d-c1c7587020d7",
   "metadata": {},
   "source": [
    "# Single module\n",
    "\n",
    "Because there is no ability to block with fastLink (in any performant way), there is only one module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2560948a-c9ca-4b96-9fa9-4c4b942689e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_linkage_cascade.start_module(\n",
    "    name=\"single_module\",\n",
    "    reference_file=geobase_reference_file,\n",
    "    reference_file_name=\"geobase_reference_file\",\n",
    "    matching_columns=[\n",
    "        \"first_name_15\",\n",
    "        \"last_name_12\",\n",
    "        \"middle_initial\",\n",
    "        \"day_of_birth\",\n",
    "        \"month_of_birth\",\n",
    "        \"year_of_birth\",\n",
    "        \"street_number\",\n",
    "        \"street_name\",\n",
    "        \"unit_number\",\n",
    "        \"zipcode\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0398ac85-1ff3-4103-979c-ff00936ced02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pass 1: regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c13afeba-9198-4546-9092-6ee563cc51e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running single_module_regular of single_module\n",
      "Files to link are 11,030 and 32,825 records\n",
      "1 blocks\n",
      "\n",
      "==================== \n",
      "fastLink(): Fast Probabilistic Record Linkage\n",
      "==================== \n",
      "\n",
      "If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\n",
      "Calculating matches for each variable.\n",
      "Getting counts for parameter estimation.\n",
      "    Parallelizing calculation using OpenMP. 3 threads out of 2 are used.\n",
      "Imputing matching probabilities using provided EM object.\n",
      "Getting the indices of estimated matches.\n",
      "    Parallelizing calculation using OpenMP. 3 threads out of 2 are used.\n",
      "Deduping the estimated matches.\n",
      "Getting the match patterns for each estimated match.\n",
      "Matched 10243 records; 7.14% still eligible to match\n"
     ]
    }
   ],
   "source": [
    "person_linkage_cascade.run_matching_pass(\n",
    "    pass_name=\"single_module_regular\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a11d9a-5e17-425f-a715-7122dfda3d7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pass 2: switched names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71d2181f-d87a-4b0a-af20-b8438a51f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_first_and_last_names(df):\n",
    "    return (\n",
    "        df.rename(columns={\"first_name\": \"last_name\", \"last_name\": \"first_name\"})\n",
    "            # Re-calculate the truncated versions of first and last.\n",
    "            # NOTE: It is not necessary to re-calculate the phonetic versions, because\n",
    "            # those are never used in any pass that has a name switch.\n",
    "            .pipe(add_truncated_name_cols)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53cb595b-85a6-4c0e-a052-1c674e3e16d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running single_module_switched_names of single_module\n",
      "Files to link are 787 and 32,825 records\n",
      "1 blocks\n",
      "\n",
      "==================== \n",
      "fastLink(): Fast Probabilistic Record Linkage\n",
      "==================== \n",
      "\n",
      "If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\n",
      "Calculating matches for each variable.\n",
      "Getting counts for parameter estimation.\n",
      "    Parallelizing calculation using OpenMP. 3 threads out of 2 are used.\n",
      "Imputing matching probabilities using provided EM object.\n",
      "Getting the indices of estimated matches.\n",
      "    Parallelizing calculation using OpenMP. 3 threads out of 2 are used.\n",
      "Deduping the estimated matches.\n",
      "Getting the match patterns for each estimated match.\n",
      "Matched 9 records; 7.05% still eligible to match\n"
     ]
    }
   ],
   "source": [
    "person_linkage_cascade.run_matching_pass(\n",
    "    pass_name=\"single_module_switched_names\",\n",
    "    input_data_transformation=switch_first_and_last_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5cc14-25bc-422c-a6ca-849b4e346d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f507b1e-61e6-448f-bc2e-afccc3020356",
   "metadata": {},
   "source": [
    "## Post-process and confirm PIKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30899aeb-e35f-4246-979c-af9f8235c3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 input records linked to deceased people, dropping links\n",
      "0 input records linked to multiple PIKs, dropping links\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id_raw_input_file</th>\n",
       "      <th>pik</th>\n",
       "      <th>record_id_census_2030</th>\n",
       "      <th>record_id_reference_file</th>\n",
       "      <th>module_name</th>\n",
       "      <th>pass_name</th>\n",
       "      <th>match_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulated_census_2030_0</td>\n",
       "      <td>89484</td>\n",
       "      <td>census_2030_preprocessed_0</td>\n",
       "      <td>simulated_geobase_reference_file_951</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simulated_census_2030_1</td>\n",
       "      <td>98736</td>\n",
       "      <td>census_2030_preprocessed_1</td>\n",
       "      <td>simulated_geobase_reference_file_17348</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simulated_census_2030_10</td>\n",
       "      <td>94481</td>\n",
       "      <td>census_2030_preprocessed_10</td>\n",
       "      <td>simulated_geobase_reference_file_9789</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simulated_census_2030_100</td>\n",
       "      <td>100835</td>\n",
       "      <td>census_2030_preprocessed_100</td>\n",
       "      <td>simulated_geobase_reference_file_21248</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simulated_census_2030_1000</td>\n",
       "      <td>93179</td>\n",
       "      <td>census_2030_preprocessed_1000</td>\n",
       "      <td>simulated_geobase_reference_file_7496</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10143</th>\n",
       "      <td>simulated_census_2030_9994</td>\n",
       "      <td>100273</td>\n",
       "      <td>census_2030_preprocessed_9994</td>\n",
       "      <td>simulated_geobase_reference_file_20169</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10144</th>\n",
       "      <td>simulated_census_2030_9996</td>\n",
       "      <td>95280</td>\n",
       "      <td>census_2030_preprocessed_9996</td>\n",
       "      <td>simulated_geobase_reference_file_11208</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10145</th>\n",
       "      <td>simulated_census_2030_9997</td>\n",
       "      <td>101556</td>\n",
       "      <td>census_2030_preprocessed_9997</td>\n",
       "      <td>simulated_geobase_reference_file_22666</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10146</th>\n",
       "      <td>simulated_census_2030_9998</td>\n",
       "      <td>98532</td>\n",
       "      <td>census_2030_preprocessed_9998</td>\n",
       "      <td>simulated_geobase_reference_file_17011</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147</th>\n",
       "      <td>simulated_census_2030_9999</td>\n",
       "      <td>105761</td>\n",
       "      <td>census_2030_preprocessed_9999</td>\n",
       "      <td>simulated_geobase_reference_file_28484</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10148 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         record_id_raw_input_file     pik          record_id_census_2030  \\\n",
       "0         simulated_census_2030_0   89484     census_2030_preprocessed_0   \n",
       "1         simulated_census_2030_1   98736     census_2030_preprocessed_1   \n",
       "2        simulated_census_2030_10   94481    census_2030_preprocessed_10   \n",
       "3       simulated_census_2030_100  100835   census_2030_preprocessed_100   \n",
       "4      simulated_census_2030_1000   93179  census_2030_preprocessed_1000   \n",
       "...                           ...     ...                            ...   \n",
       "10143  simulated_census_2030_9994  100273  census_2030_preprocessed_9994   \n",
       "10144  simulated_census_2030_9996   95280  census_2030_preprocessed_9996   \n",
       "10145  simulated_census_2030_9997  101556  census_2030_preprocessed_9997   \n",
       "10146  simulated_census_2030_9998   98532  census_2030_preprocessed_9998   \n",
       "10147  simulated_census_2030_9999  105761  census_2030_preprocessed_9999   \n",
       "\n",
       "                     record_id_reference_file    module_name  \\\n",
       "0        simulated_geobase_reference_file_951  single_module   \n",
       "1      simulated_geobase_reference_file_17348  single_module   \n",
       "2       simulated_geobase_reference_file_9789  single_module   \n",
       "3      simulated_geobase_reference_file_21248  single_module   \n",
       "4       simulated_geobase_reference_file_7496  single_module   \n",
       "...                                       ...            ...   \n",
       "10143  simulated_geobase_reference_file_20169  single_module   \n",
       "10144  simulated_geobase_reference_file_11208  single_module   \n",
       "10145  simulated_geobase_reference_file_22666  single_module   \n",
       "10146  simulated_geobase_reference_file_17011  single_module   \n",
       "10147  simulated_geobase_reference_file_28484  single_module   \n",
       "\n",
       "                   pass_name  match_probability  \n",
       "0      single_module_regular           1.000000  \n",
       "1      single_module_regular           1.000000  \n",
       "2      single_module_regular           0.999999  \n",
       "3      single_module_regular           1.000000  \n",
       "4      single_module_regular           0.999999  \n",
       "...                      ...                ...  \n",
       "10143  single_module_regular           0.999995  \n",
       "10144  single_module_regular           1.000000  \n",
       "10145  single_module_regular           1.000000  \n",
       "10146  single_module_regular           1.000000  \n",
       "10147  single_module_regular           1.000000  \n",
       "\n",
       "[10148 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_linkage_cascade.confirm_piks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0eea4fa2-588b-4555-a78e-8747da8db6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "module_name    pass_name                   \n",
       "single_module  single_module_regular           10140\n",
       "               single_module_switched_names        8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_linkage_cascade.confirmed_piks.groupby([\"module_name\", \"pass_name\"]).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "668b096b-eb2d-4160-a1a8-f76ab84ccf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id_raw_input_file</th>\n",
       "      <th>pik</th>\n",
       "      <th>record_id_census_2030</th>\n",
       "      <th>record_id_reference_file</th>\n",
       "      <th>module_name</th>\n",
       "      <th>pass_name</th>\n",
       "      <th>match_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulated_census_2030_0</td>\n",
       "      <td>89484</td>\n",
       "      <td>census_2030_preprocessed_0</td>\n",
       "      <td>simulated_geobase_reference_file_951</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simulated_census_2030_1</td>\n",
       "      <td>98736</td>\n",
       "      <td>census_2030_preprocessed_1</td>\n",
       "      <td>simulated_geobase_reference_file_17348</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simulated_census_2030_10</td>\n",
       "      <td>94481</td>\n",
       "      <td>census_2030_preprocessed_10</td>\n",
       "      <td>simulated_geobase_reference_file_9789</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simulated_census_2030_100</td>\n",
       "      <td>100835</td>\n",
       "      <td>census_2030_preprocessed_100</td>\n",
       "      <td>simulated_geobase_reference_file_21248</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simulated_census_2030_1000</td>\n",
       "      <td>93179</td>\n",
       "      <td>census_2030_preprocessed_1000</td>\n",
       "      <td>simulated_geobase_reference_file_7496</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10143</th>\n",
       "      <td>simulated_census_2030_9994</td>\n",
       "      <td>100273</td>\n",
       "      <td>census_2030_preprocessed_9994</td>\n",
       "      <td>simulated_geobase_reference_file_20169</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10144</th>\n",
       "      <td>simulated_census_2030_9996</td>\n",
       "      <td>95280</td>\n",
       "      <td>census_2030_preprocessed_9996</td>\n",
       "      <td>simulated_geobase_reference_file_11208</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10145</th>\n",
       "      <td>simulated_census_2030_9997</td>\n",
       "      <td>101556</td>\n",
       "      <td>census_2030_preprocessed_9997</td>\n",
       "      <td>simulated_geobase_reference_file_22666</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10146</th>\n",
       "      <td>simulated_census_2030_9998</td>\n",
       "      <td>98532</td>\n",
       "      <td>census_2030_preprocessed_9998</td>\n",
       "      <td>simulated_geobase_reference_file_17011</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147</th>\n",
       "      <td>simulated_census_2030_9999</td>\n",
       "      <td>105761</td>\n",
       "      <td>census_2030_preprocessed_9999</td>\n",
       "      <td>simulated_geobase_reference_file_28484</td>\n",
       "      <td>single_module</td>\n",
       "      <td>single_module_regular</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10148 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         record_id_raw_input_file     pik          record_id_census_2030  \\\n",
       "0         simulated_census_2030_0   89484     census_2030_preprocessed_0   \n",
       "1         simulated_census_2030_1   98736     census_2030_preprocessed_1   \n",
       "2        simulated_census_2030_10   94481    census_2030_preprocessed_10   \n",
       "3       simulated_census_2030_100  100835   census_2030_preprocessed_100   \n",
       "4      simulated_census_2030_1000   93179  census_2030_preprocessed_1000   \n",
       "...                           ...     ...                            ...   \n",
       "10143  simulated_census_2030_9994  100273  census_2030_preprocessed_9994   \n",
       "10144  simulated_census_2030_9996   95280  census_2030_preprocessed_9996   \n",
       "10145  simulated_census_2030_9997  101556  census_2030_preprocessed_9997   \n",
       "10146  simulated_census_2030_9998   98532  census_2030_preprocessed_9998   \n",
       "10147  simulated_census_2030_9999  105761  census_2030_preprocessed_9999   \n",
       "\n",
       "                     record_id_reference_file    module_name  \\\n",
       "0        simulated_geobase_reference_file_951  single_module   \n",
       "1      simulated_geobase_reference_file_17348  single_module   \n",
       "2       simulated_geobase_reference_file_9789  single_module   \n",
       "3      simulated_geobase_reference_file_21248  single_module   \n",
       "4       simulated_geobase_reference_file_7496  single_module   \n",
       "...                                       ...            ...   \n",
       "10143  simulated_geobase_reference_file_20169  single_module   \n",
       "10144  simulated_geobase_reference_file_11208  single_module   \n",
       "10145  simulated_geobase_reference_file_22666  single_module   \n",
       "10146  simulated_geobase_reference_file_17011  single_module   \n",
       "10147  simulated_geobase_reference_file_28484  single_module   \n",
       "\n",
       "                   pass_name  match_probability  \n",
       "0      single_module_regular           1.000000  \n",
       "1      single_module_regular           1.000000  \n",
       "2      single_module_regular           0.999999  \n",
       "3      single_module_regular           1.000000  \n",
       "4      single_module_regular           0.999999  \n",
       "...                      ...                ...  \n",
       "10143  single_module_regular           0.999995  \n",
       "10144  single_module_regular           1.000000  \n",
       "10145  single_module_regular           1.000000  \n",
       "10146  single_module_regular           1.000000  \n",
       "10147  single_module_regular           1.000000  \n",
       "\n",
       "[10148 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_linkage_cascade.confirmed_piks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ba651-913d-4eb4-9d3a-e391b9efc8d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Resulting PIKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7a239d1-e1d8-435d-9af5-7c71ba3d64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pik_values = (\n",
    "    person_linkage_cascade.confirmed_piks\n",
    "        .rename(columns={\"record_id_raw_input_file\": \"record_id\"})[[\"record_id\", \"pik\"]]\n",
    "        .drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9271823-d2b3-4f41-9d77-9ad5bb117397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>household_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_initial</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>street_number</th>\n",
       "      <th>street_name</th>\n",
       "      <th>unit_number</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>housing_type</th>\n",
       "      <th>relationship_to_reference_person</th>\n",
       "      <th>sex</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>year</th>\n",
       "      <th>pik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulated_census_2030_0</td>\n",
       "      <td>0_8033</td>\n",
       "      <td>Gerald</td>\n",
       "      <td>R</td>\n",
       "      <td>Allen</td>\n",
       "      <td>86</td>\n",
       "      <td>11/03/1943</td>\n",
       "      <td>1130</td>\n",
       "      <td>mallory ln</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2030</td>\n",
       "      <td>89484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simulated_census_2030_1</td>\n",
       "      <td>0_1066</td>\n",
       "      <td>April</td>\n",
       "      <td>S</td>\n",
       "      <td>Hayden</td>\n",
       "      <td>33</td>\n",
       "      <td>10/23/1996</td>\n",
       "      <td>32597</td>\n",
       "      <td>delacorte dr</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Other nonrelative</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>2030</td>\n",
       "      <td>98736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simulated_census_2030_2</td>\n",
       "      <td>0_1066</td>\n",
       "      <td>Loretta</td>\n",
       "      <td>T</td>\n",
       "      <td>Lowe</td>\n",
       "      <td>71</td>\n",
       "      <td>06/01/1958</td>\n",
       "      <td>32597</td>\n",
       "      <td>delacorte dr</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2030</td>\n",
       "      <td>91258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simulated_census_2030_3</td>\n",
       "      <td>0_2514</td>\n",
       "      <td>Sandra</td>\n",
       "      <td>A</td>\n",
       "      <td>Sorrentino</td>\n",
       "      <td>75</td>\n",
       "      <td>03/18/1954</td>\n",
       "      <td>4458</td>\n",
       "      <td>wibdsor pl</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Female</td>\n",
       "      <td>Multiracial or Other</td>\n",
       "      <td>2030</td>\n",
       "      <td>90622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simulated_census_2030_4</td>\n",
       "      <td>0_5627</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>S</td>\n",
       "      <td>Baker</td>\n",
       "      <td>44</td>\n",
       "      <td>05/20/1985</td>\n",
       "      <td>None</td>\n",
       "      <td>winding trail rd</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Other nonrelative</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>2030</td>\n",
       "      <td>96379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11024</th>\n",
       "      <td>simulated_census_2030_11024</td>\n",
       "      <td>0_10778</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>T</td>\n",
       "      <td>Boyd</td>\n",
       "      <td>46</td>\n",
       "      <td>07/01/1983</td>\n",
       "      <td>211</td>\n",
       "      <td>quiet wsy</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2030</td>\n",
       "      <td>95963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11025</th>\n",
       "      <td>simulated_census_2030_11025</td>\n",
       "      <td>0_11001</td>\n",
       "      <td>Wendy</td>\n",
       "      <td>M</td>\n",
       "      <td>Gross</td>\n",
       "      <td>54</td>\n",
       "      <td>12/05/1975</td>\n",
       "      <td>2801</td>\n",
       "      <td>blje rdv dr n</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2030</td>\n",
       "      <td>94444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11026</th>\n",
       "      <td>simulated_census_2030_11026</td>\n",
       "      <td>0_5308</td>\n",
       "      <td>Ember</td>\n",
       "      <td>H</td>\n",
       "      <td>Samuels</td>\n",
       "      <td>10</td>\n",
       "      <td>10/26/2019</td>\n",
       "      <td>24113</td>\n",
       "      <td>lauder</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>2030</td>\n",
       "      <td>104164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027</th>\n",
       "      <td>simulated_census_2030_11027</td>\n",
       "      <td>0_10693</td>\n",
       "      <td>Athena</td>\n",
       "      <td>V</td>\n",
       "      <td>Deshpande</td>\n",
       "      <td>27</td>\n",
       "      <td>07/05/2002</td>\n",
       "      <td>1534</td>\n",
       "      <td>bentley dr</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>2030</td>\n",
       "      <td>106182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11028</th>\n",
       "      <td>simulated_census_2030_11028</td>\n",
       "      <td>0_10693</td>\n",
       "      <td>Zechariah</td>\n",
       "      <td>C</td>\n",
       "      <td>Deshpande</td>\n",
       "      <td>0</td>\n",
       "      <td>04/10/2029</td>\n",
       "      <td>1534</td>\n",
       "      <td>bentley dr</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Biological child</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>2030</td>\n",
       "      <td>107923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11029 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         record_id household_id first_name middle_initial  \\\n",
       "0          simulated_census_2030_0       0_8033     Gerald              R   \n",
       "1          simulated_census_2030_1       0_1066      April              S   \n",
       "2          simulated_census_2030_2       0_1066    Loretta              T   \n",
       "3          simulated_census_2030_3       0_2514     Sandra              A   \n",
       "4          simulated_census_2030_4       0_5627      Bobby              S   \n",
       "...                            ...          ...        ...            ...   \n",
       "11024  simulated_census_2030_11024      0_10778     Jeremy              T   \n",
       "11025  simulated_census_2030_11025      0_11001      Wendy              M   \n",
       "11026  simulated_census_2030_11026       0_5308      Ember              H   \n",
       "11027  simulated_census_2030_11027      0_10693     Athena              V   \n",
       "11028  simulated_census_2030_11028      0_10693  Zechariah              C   \n",
       "\n",
       "        last_name age date_of_birth street_number       street_name  \\\n",
       "0           Allen  86    11/03/1943          1130        mallory ln   \n",
       "1          Hayden  33    10/23/1996         32597      delacorte dr   \n",
       "2            Lowe  71    06/01/1958         32597      delacorte dr   \n",
       "3      Sorrentino  75    03/18/1954          4458        wibdsor pl   \n",
       "4           Baker  44    05/20/1985          None  winding trail rd   \n",
       "...           ...  ..           ...           ...               ...   \n",
       "11024        Boyd  46    07/01/1983           211         quiet wsy   \n",
       "11025       Gross  54    12/05/1975          2801     blje rdv dr n   \n",
       "11026     Samuels  10    10/26/2019         24113            lauder   \n",
       "11027   Deshpande  27    07/05/2002          1534        bentley dr   \n",
       "11028   Deshpande   0    04/10/2029          1534        bentley dr   \n",
       "\n",
       "      unit_number     city state zipcode housing_type  \\\n",
       "0            None  Anytown    WA   00000    Household   \n",
       "1            None  Anytown    WA   00000    Household   \n",
       "2            None  Anytown    WA   00000    Household   \n",
       "3            None  Anytown    WA   00000    Household   \n",
       "4            None  Anytown    WA   00000    Household   \n",
       "...           ...      ...   ...     ...          ...   \n",
       "11024        None  Anytown    WA   00000    Household   \n",
       "11025        None  Anytown    WA   00000    Household   \n",
       "11026        None  Anytown    WA   00000    Household   \n",
       "11027        None  Anytown    WA   00000    Household   \n",
       "11028        None  Anytown    WA   00000    Household   \n",
       "\n",
       "      relationship_to_reference_person     sex        race_ethnicity  year  \\\n",
       "0                     Reference person    Male                 Black  2030   \n",
       "1                    Other nonrelative  Female                 Black  2030   \n",
       "2                     Reference person  Female                 White  2030   \n",
       "3                     Reference person  Female  Multiracial or Other  2030   \n",
       "4                    Other nonrelative    Male                 White  2030   \n",
       "...                                ...     ...                   ...   ...   \n",
       "11024                 Reference person    Male                 Black  2030   \n",
       "11025                 Reference person  Female                 White  2030   \n",
       "11026                 Reference person  Female                 Black  2030   \n",
       "11027                 Reference person  Female                 Asian  2030   \n",
       "11028                 Biological child    Male                 Asian  2030   \n",
       "\n",
       "          pik  \n",
       "0       89484  \n",
       "1       98736  \n",
       "2       91258  \n",
       "3       90622  \n",
       "4       96379  \n",
       "...       ...  \n",
       "11024   95963  \n",
       "11025   94444  \n",
       "11026  104164  \n",
       "11027  106182  \n",
       "11028  107923  \n",
       "\n",
       "[11029 rows x 19 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_2030_piked = census_2030_raw_input.copy()\n",
    "census_2030_piked = census_2030_piked.merge(\n",
    "    pik_values,\n",
    "    how=\"left\",\n",
    "    on=\"record_id\",\n",
    "    validate=\"1:1\",\n",
    ")\n",
    "census_2030_piked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e6566f0-e77b-4b21-968c-05a7ef08eff6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.01% of the input records were PIKed\n"
     ]
    }
   ],
   "source": [
    "piked_proportion = census_2030_piked.pik.notnull().mean()\n",
    "# Compare with 90.28% of input records PIKed in the 2010 CUF,\n",
    "# as reported in Wagner and Layne, Table 2, p. 18 \n",
    "print(f'{piked_proportion:.2%} of the input records were PIKed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffc185e2-1d4e-4d8c-98a0-3c0c3d1641cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2030_piked.to_parquet(f'{output_dir}/{data_to_use}/census_2030_piked.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "822eb452-ca69-48fc-b1d6-c3425fd5f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_linkage_cascade.confirmed_piks.to_parquet(f'{output_dir}/{data_to_use}/confirmed_piks.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee7cdb-bac3-4245-b1e1-0cdcb6652a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
